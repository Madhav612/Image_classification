{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fb76fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import cm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import torchvision # load datasets\n",
    "import torchvision.transforms as transforms # transform data\n",
    "import torch.nn as nn # basic building block for neural neteorks\n",
    "import torch.nn.functional as F # import convolution functions like Relu\n",
    "import torch.optim as optim # optimzer\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.cuda.empty_cache()\n",
    "import os\n",
    "import glob\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda:0\")\n",
    "# torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff42dfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2,perplexity=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e839152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TRAIN_DATA_PATH = \"/content/drive/MyDrive/RA/\"\n",
    "TRAIN_DATA_PATH = \"data\"\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 0.003\n",
    "EPOCHS = 25\n",
    "# mean, stf = get_mean_and_std(train_iter_loader) #We call this function after initializing the dataloader\n",
    "mean = [0.8249, 0.8083, 0.8291]#calculated using the function above\n",
    "std = [0.1698, 0.1917, 0.1764]#calculated using the fucntion above\n",
    "TRANSFORM_IMG_train = transforms.Compose([\n",
    "    transforms.Resize((512,512)),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomRotation(10),\n",
    "#     transforms.RandomVerticalFlip(),\n",
    "    # transforms.Resize(256),\n",
    "    # transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.Tensor(mean),torch.Tensor(std))\n",
    "    ])\n",
    "TRANSFORM_IMG_test = transforms.Compose([\n",
    "    transforms.Resize((512,512)),\n",
    "    # transforms.Resize(256),\n",
    "    # transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(torch.Tensor(mean),torch.Tensor(std))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e843a783",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob('data/train/'+ \"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06102311",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e23249",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for folder in file_list:\n",
    "    files = glob.glob( folder+ \"/*.tif\")\n",
    "    counter+=len(files)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cf1395",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26377db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter_folder = torchvision.datasets.ImageFolder(os.path.join(TRAIN_DATA_PATH, 'train'), transform=TRANSFORM_IMG_train)\n",
    "# train_iter_folder = torchvision.datasets.ImageFolder(os.path.join(TRAIN_DATA_PATH, 'train'))\n",
    "train_iter_loader = DataLoader(train_iter_folder,batch_size = 100,shuffle=True,generator=torch.Generator(device='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dcadfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {'colon': 0,'endometrium_1': 1,'endometrium_2': 2,'kidney': 3,\n",
    "'liver': 4,'lung': 5,'lymph_node': 6,'pancreas': 7,'skin_1': 8,'skin_2': 9,'small_intestine': 10,'spleen': 11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa34ee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16*125*125,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3  = nn.Linear(84,len(classes))\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1,16*125*125)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0807dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9982e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feffde66",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('CNS_75_RA_scratch_transform_512_trial1.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9de294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct = 0\n",
    "# total = 0\n",
    "# actual = []\n",
    "# predicted_list = []\n",
    "# with torch.no_grad():\n",
    "#     for _,(image,label) in enumerate(test_iter_loader):\n",
    "#         images = image.to(device)\n",
    "#         labels = label.to(device)\n",
    "#         outputs = net(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         for i in range(len(predicted)):\n",
    "#             actual.append(labels[i].view(-1).detach().cpu().numpy())\n",
    "#             predicted_list.append(predicted[i].view(-1).detach().cpu().numpy())\n",
    "# #         actual.append(labels)\n",
    "# #         predicted_list.append(predicted)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "# # \n",
    "# print('Accuracy of the network on the test images: %d %%' % (\n",
    "#     100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf13a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = torch.zeros((0, 1, 512, 512),device = torch.device(\"cuda:0\"))\n",
    "test_predictions = []\n",
    "test_targets = []\n",
    "test_embeddings = torch.zeros((0, 200), device = torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80fda6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in train_iter_loader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    embeddings, logits = net(x)\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    test_predictions.extend(preds.detach().cpu().tolist())\n",
    "    test_targets.extend(y.detach().cpu().tolist())\n",
    "    test_embeddings = torch.cat((test_embeddings, embeddings.detach().cpu()), 0)\n",
    "    test_imgs = torch.cat((test_imgs, x.detach().cpu()), 0)\n",
    "test_imgs = np.array(test_imgs)\n",
    "test_embeddings = np.array(test_embeddings)\n",
    "test_targets = np.array(test_targets)\n",
    "test_predictions = np.array(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd62ce7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15edf690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4da00e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd118e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8440f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f50299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f8c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image,label in train_iter_loader:\n",
    "    tsne_result = tsne.fit_transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a38d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244551bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(2, verbose=1)\n",
    "tsne_proj = tsne.fit_transform(test_embeddings)\n",
    "# Plot those points as a scatter plot and label them based on the pred labels\n",
    "cmap = cm.get_cmap('tab20')\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "num_categories = 10\n",
    "for lab in range(num_categories):\n",
    "    indices = test_predictions==lab\n",
    "    ax.scatter(tsne_proj[indices,0],tsne_proj[indices,1], c=np.array(cmap(lab)).reshape(1,4), label = lab ,alpha=0.5)\n",
    "ax.legend(fontsize='large', markerscale=2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
